 with:
    file-path: ./../../../od-gha-files/sql-actions.ps1
    destination-path: C:\\Temp\\GlobalTaxMapperDB
    aws-region: us-west-2
  env:
    ADD_ARTIFACTS_TO_RELEASE: true
    AWS_REGION: us-west-2
    DACPAC_ENVIRONMENT: testbox
    DB_NAME: GlobalTaxMapper_Restore
    DEPLOYMENT_ROLE_ARN: arn:aws:iam::192337955983:role/deployment-test-GlobalTaxMapper.DB
    GITHUB_ENVIRONMENT: test
    MATRIX_INSTANCE_LIST: {"instance":"i-00df312345678986","dbServerName":"ABCD-EFGHIJK.uat.aws.abc.com","role":"primary"}
    MULTI_SUBNET_FAILOVER: true
    NEW_RELIC_APP_KEY: 1962024
    NEW_RELIC_API_KEY: ***
    NR_ENVIRONMENT: testbox
    NUGET_CONTRIBUTORS_PACKAGE_PATH: C:\GlobalTaxMapperDB\Contributors
    NUGET_PACKAGE_PATH: C:\abc\releases\databases\GlobalTaxMapperDB
    OD_GHA_FILE_PATH: od-gha-files
    OIDC_ROLE_ARN: arn:aws:iam::357642245240:role/gha-oidc-preprod-GlobalTaxMapper.DB
    OWNER: clouddata@abc.com
    PUBLISH_PROFILE_FILE_NAME: uat.GlobalTaxMapperDB.publish.xml
    RELEASE_NUMBER: 0.0.0.107
    SLACK_CHANNEL: slack-test-expense
    SLACK_WEBHOOK_URL: ***
    SQLPACKAGE_DIR: C:\actions-runner\_work\GlobalTaxMapper.DB\GlobalTaxMapper.DB\sqlpackage
    SQL_CMD_VARIABLES: {"QueryStoreCaptureMode": "NONE", "QueryStoreMaxStorageSize": "100", "QueryStoreStaleQueryThresholdDays": "15", "QueryStoreState": "OFF"}
    SQL_PACKAGE_DEPLOY_PROPERTIES: {"AdditionalDeploymentContributorArguments":"CreateIndexOperationalPropsModifier.Online=ON;CreateIndexOperationalPropsModifier.MAXDOP=2"}
    SQL_PACKAGE_PARAMETERS:  
    SQL_PASSWORD_PARAMETER_STORE: GlobalTaxMapperDB_SQL_Password
    SQL_USER_NAME: GlobalTaxMapperDBGHAUser
    TARGET_SERVERS: globaltaxmapper.db.livestage6.test.abc.com.
    USE_CLUSTER_NAMES: false
    abc_RUNNER_DEPLOYTRACK_TOKEN: ***
    ENV_NAME_EXTRACTED: test
    AWS_DEFAULT_REGION: us-west-2
    AWS_ACCESS_KEY_ID: ***
    AWS_SECRET_ACCESS_KEY: ***
    AWS_SESSION_TOKEN: ***
    SQLPACKAGE_PATH: C:\actions-runner\_work\GlobalTaxMapper.DB\GlobalTaxMapper.DB\sqlpackage
    ROLE_LIST: "primary"
Run set -e
  set -e
  
  echo "Starting script transfer..."
  
  # Encode the file to base64
  ENCODED=$(base64 -w 0 "./../../../od-gha-files/sql-actions.ps1")
  
  # Build the PowerShell command
  PS_COMMAND="\$b64='$ENCODED'; \
  if (!(Test-Path 'C:\\Temp\\GlobalTaxMapperDB')) { New-Item -Path 'C:\\Temp\\GlobalTaxMapperDB' -ItemType Directory | Out-Null }; \
  \$scriptPath = Join-Path 'C:\\Temp\\GlobalTaxMapperDB' 'sql-actions.ps1'; \
  if (Test-Path \$scriptPath) { Remove-Item \$scriptPath -Force; Write-Output 'FILE_DELETED' }; \
  \$decoded = [System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String(\$b64)); \
  Set-Content -Path \$scriptPath -Value \$decoded -Force; \
  Write-Output 'FILE_UPLOADED'"
  
  # Normalize matrix instance list
  matrixJson="$MATRIX_INSTANCE_LIST"
  if [[ "$matrixJson" != \[* ]]; then
    echo "Wrapping single JSON object in an array..."
    matrixJson=$(echo "$matrixJson" | jq -c '[.]')
  fi
  
  echo "Raw MATRIX_INSTANCE_LIST: $matrixJson"
  
  # Iterate over each instance
  echo "$matrixJson" | jq -c '.[]' | while read -r item; do
    instance=$(echo "$item" | jq -r '.instance')
    dbServer=$(echo "$item" | jq -r '.dbServerName')
    role=$(echo "$item" | jq -r '.role')
  
    echo "----------------------------------"
    echo "Transferring script to - Instance: $instance, Role: $role, DB Server: $dbServer"
  
    # Send the transfer command
    command_id=$(aws ssm send-command \
      --document-name "AWS-RunPowerShellScript" \
      --instance-ids "$instance" \
      --region "us-west-2" \
      --comment "Uploading sql-actions.ps1 via GitHub Actions" \
      --parameters "commands=[\"$PS_COMMAND\"]" \
      --query "Command.CommandId" \
      --output text)
  
    echo "Command ID generated: $command_id"
  
    # Wait for upload to complete
    echo "Waiting for upload to complete..."
    timeout_minutes=5
    timeout_seconds=$((timeout_minutes * 60))
    elapsed_seconds=0
  
    while true; do
      status=$(aws ssm list-command-invocations \
        --command-id "$command_id" \
        --instance-id "$instance" \
        --region "us-west-2" \
        --query "CommandInvocations[0].Status" \
        --output text)
  
      echo "Current SSM command status for $instance: $status"
  
      if [[ "$status" == "Success" ]]; then
        echo "Script upload completed successfully for instance: $instance"
        break
      elif [[ "$status" == "Failed" || "$status" == "Cancelled" || "$status" == "TimedOut" ]]; then
        echo "Script upload failed for instance: $instance with status: $status"
        exit 1
      else
        echo "Still waiting for script upload... ($elapsed_seconds seconds elapsed)"
        sleep 5
        elapsed_seconds=$((elapsed_seconds + 5))
        if [[ "$elapsed_seconds" -ge "$timeout_seconds" ]]; then
          echo "Timeout reached ($timeout_minutes minutes) while waiting for script upload on instance: $instance"
          exit 1
        fi
      fi
    done
  
    echo "----------------------------------"
  done
  
  echo "All scripts uploaded successfully to all instances."
  shell: C:\Program Files\Git\usr\bin\bash.EXE --noprofile --norc -e -o pipefail {0}
  env:
    ADD_ARTIFACTS_TO_RELEASE: true
    AWS_REGION: us-west-2
    DACPAC_ENVIRONMENT: testbox
    DB_NAME: GlobalTaxMapper_Restore
    DEPLOYMENT_ROLE_ARN: arn:aws:iam::192337955983:role/deployment-test-GlobalTaxMapper.DB
    GITHUB_ENVIRONMENT: test
    MATRIX_INSTANCE_LIST: {"instance":"i-00df312345678986","dbServerName":"ABCD-EFGHIJK.uat.aws.abc.com","role":"primary"}
    MULTI_SUBNET_FAILOVER: true
    NEW_RELIC_APP_KEY: 1962024
    NEW_RELIC_API_KEY: ***
    NR_ENVIRONMENT: testbox
    NUGET_CONTRIBUTORS_PACKAGE_PATH: C:\GlobalTaxMapperDB\Contributors
    NUGET_PACKAGE_PATH: C:\abc\releases\databases\GlobalTaxMapperDB
    OD_GHA_FILE_PATH: od-gha-files
    OIDC_ROLE_ARN: arn:aws:iam::357642245240:role/gha-oidc-preprod-GlobalTaxMapper.DB
    OWNER: clouddata@abc.com
    PUBLISH_PROFILE_FILE_NAME: uat.GlobalTaxMapperDB.publish.xml
    RELEASE_NUMBER: 0.0.0.107
    SLACK_CHANNEL: slack-test-expense
    SLACK_WEBHOOK_URL: ***
    SQLPACKAGE_DIR: C:\actions-runner\_work\GlobalTaxMapper.DB\GlobalTaxMapper.DB\sqlpackage
    SQL_CMD_VARIABLES: {"QueryStoreCaptureMode": "NONE", "QueryStoreMaxStorageSize": "100", "QueryStoreStaleQueryThresholdDays": "15", "QueryStoreState": "OFF"}
    SQL_PACKAGE_DEPLOY_PROPERTIES: {"AdditionalDeploymentContributorArguments":"CreateIndexOperationalPropsModifier.Online=ON;CreateIndexOperationalPropsModifier.MAXDOP=2"}
    SQL_PACKAGE_PARAMETERS:  
    SQL_PASSWORD_PARAMETER_STORE: GlobalTaxMapperDB_SQL_Password
    SQL_USER_NAME: GlobalTaxMapperDBGHAUser
    TARGET_SERVERS: globaltaxmapper.db.livestage6.test.abc.com.
    USE_CLUSTER_NAMES: false
    abc_RUNNER_DEPLOYTRACK_TOKEN: ***
    ENV_NAME_EXTRACTED: test
    AWS_DEFAULT_REGION: us-west-2
    AWS_ACCESS_KEY_ID: ***
    AWS_SECRET_ACCESS_KEY: ***
    AWS_SESSION_TOKEN: ***
    SQLPACKAGE_PATH: C:\actions-runner\_work\GlobalTaxMapper.DB\GlobalTaxMapper.DB\sqlpackage
    ROLE_LIST: "primary"
Starting script transfer...
base64: ./../../../od-gha-files/sql-actions.ps1: No such file or directory
Error: Process completed with exit code 1.
